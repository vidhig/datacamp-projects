{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', 500)\n",
    "# pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.width', 1000)\n",
    "\n",
    "# np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data\n",
    "df = pd.read_csv('fake_or_real_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a series to store the labels: y [response variable]\n",
    "y = df.label\n",
    "\n",
    "## create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], y, test_size = 0.33, random_state = 53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '0000',\n",
       " '00000031',\n",
       " '000035',\n",
       " '00006',\n",
       " '0001',\n",
       " '0001pt',\n",
       " '000ft',\n",
       " '000km']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## initialize a CountVectorizer object: count_vectorizer\n",
    "### CountVectorizer will be used to get bag of words vector and remove the stop words\n",
    "count_vectorizer = CountVectorizer(stop_words = 'english')\n",
    "\n",
    "## transform the training data using only the 'text' column values: count_train\n",
    "### fit and transform the data\n",
    "### creates the bag of words vectors\n",
    "### generates mapping of words with ids and vectors representing how many times each word appears in the movie plot\n",
    "### fit_transform works differently for different models but generally\n",
    "### fit will find parameters in the data\n",
    "### transform will apply the model's underlying algorithm or approximation\n",
    "### here, we are going to create a bag of words dictionary and vector for each document using the training data\n",
    "count_train = count_vectorizer.fit_transform(X_train.values)\n",
    "\n",
    "## transform the test data using only the 'text' column values: count_test\n",
    "### transform will create bag of words vectors for the test data using the same dictionary\n",
    "### train and test need to use a consistent set of words so that the trained model can understand the test input\n",
    "count_test = count_vectorizer.transform(X_test.values)\n",
    "\n",
    "## print the first 10 features of the count_vectorizer\n",
    "count_vectorizer.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '0000',\n",
       " '00000031',\n",
       " '000035',\n",
       " '00006',\n",
       " '0001',\n",
       " '0001pt',\n",
       " '000ft',\n",
       " '000km',\n",
       " '001',\n",
       " '0011',\n",
       " '002',\n",
       " '003',\n",
       " '004',\n",
       " '006',\n",
       " '006s',\n",
       " '007',\n",
       " '007s',\n",
       " '008',\n",
       " '008s',\n",
       " '009',\n",
       " '0099',\n",
       " '00am',\n",
       " '00p',\n",
       " '00pm',\n",
       " '01',\n",
       " '010',\n",
       " '013',\n",
       " '014',\n",
       " '015',\n",
       " '016',\n",
       " '018',\n",
       " '01am',\n",
       " '02',\n",
       " '020',\n",
       " '022',\n",
       " '023',\n",
       " '024',\n",
       " '025',\n",
       " '027',\n",
       " '028',\n",
       " '02welcome',\n",
       " '03',\n",
       " '031',\n",
       " '032',\n",
       " '0325',\n",
       " '033',\n",
       " '034',\n",
       " '035',\n",
       " '037',\n",
       " '039',\n",
       " '03eb',\n",
       " '04',\n",
       " '040',\n",
       " '0400',\n",
       " '042',\n",
       " '044',\n",
       " '048',\n",
       " '049',\n",
       " '04pm',\n",
       " '05',\n",
       " '0509245d29',\n",
       " '052',\n",
       " '056',\n",
       " '06',\n",
       " '062',\n",
       " '066',\n",
       " '068',\n",
       " '06pm',\n",
       " '07',\n",
       " '0700',\n",
       " '075',\n",
       " '076',\n",
       " '079',\n",
       " '07dryempjx',\n",
       " '08',\n",
       " '080',\n",
       " '081',\n",
       " '082',\n",
       " '084',\n",
       " '089',\n",
       " '0891',\n",
       " '09',\n",
       " '098263',\n",
       " '09am',\n",
       " '09pm',\n",
       " '0_jgdktlmn',\n",
       " '0a_merrill',\n",
       " '0d',\n",
       " '0fjjvowyhg8qtskiz',\n",
       " '0h4at2yetra17uxetni02ls2jeg0mty45jrcu7mrzsrpcbq464i',\n",
       " '0hq3vb2giv',\n",
       " '0in',\n",
       " '0jsn6pjkan',\n",
       " '0oeekvljlt',\n",
       " '0pt',\n",
       " '0t5',\n",
       " '0txrbwvobzz4fi5nksw6k5a6cxzbb3juxthmdiz93cby8gvrqiypzhajvjnt2',\n",
       " '0womdwalmi',\n",
       " '0x',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '10009020',\n",
       " '1000s',\n",
       " '1001',\n",
       " '10021',\n",
       " '10028',\n",
       " '100515p',\n",
       " '100bn',\n",
       " '100c',\n",
       " '100k',\n",
       " '100m',\n",
       " '100percentfedup',\n",
       " '100s',\n",
       " '100th',\n",
       " '101',\n",
       " '1010359',\n",
       " '1019',\n",
       " '101st',\n",
       " '102',\n",
       " '1024026',\n",
       " '1026',\n",
       " '102816',\n",
       " '102836002',\n",
       " '102k',\n",
       " '102m',\n",
       " '103',\n",
       " '1033',\n",
       " '103rd',\n",
       " '104',\n",
       " '1040',\n",
       " '104396002',\n",
       " '104893',\n",
       " '105',\n",
       " '106',\n",
       " '106116001',\n",
       " '107',\n",
       " '1070',\n",
       " '107th',\n",
       " '108',\n",
       " '109',\n",
       " '1095',\n",
       " '1098',\n",
       " '10bn',\n",
       " '10ft',\n",
       " '10kb',\n",
       " '10m',\n",
       " '10m54s',\n",
       " '10mm',\n",
       " '10pm',\n",
       " '10th',\n",
       " '10ths',\n",
       " '10x',\n",
       " '10yrs',\n",
       " '11',\n",
       " '110',\n",
       " '1100',\n",
       " '1101',\n",
       " '110136001',\n",
       " '1105',\n",
       " '111',\n",
       " '112',\n",
       " '1121',\n",
       " '112145924',\n",
       " '1122930jg',\n",
       " '112th',\n",
       " '113',\n",
       " '113bn',\n",
       " '114',\n",
       " '1146',\n",
       " '114th',\n",
       " '115',\n",
       " '11540',\n",
       " '115aug',\n",
       " '115th',\n",
       " '116',\n",
       " '1160',\n",
       " '117',\n",
       " '11702',\n",
       " '1176',\n",
       " '118',\n",
       " '1180',\n",
       " '119',\n",
       " '1190',\n",
       " '11am',\n",
       " '11cm',\n",
       " '11mn',\n",
       " '11pm',\n",
       " '11th',\n",
       " '11truther',\n",
       " '12',\n",
       " '120',\n",
       " '1200',\n",
       " '1207',\n",
       " '121',\n",
       " '122',\n",
       " '1228',\n",
       " '123',\n",
       " '12333',\n",
       " '123421',\n",
       " '12345',\n",
       " '124',\n",
       " '125',\n",
       " '1252',\n",
       " '126',\n",
       " '12619print',\n",
       " '1265',\n",
       " '127',\n",
       " '127million',\n",
       " '128',\n",
       " '1280',\n",
       " '1287',\n",
       " '128th',\n",
       " '129',\n",
       " '12hdlgeeua87t2ju8m4tbro247yj5u2tvp',\n",
       " '12k',\n",
       " '12m',\n",
       " '12mn',\n",
       " '12pm',\n",
       " '12sso1zj2bbdguiraddmamlnets7oc1',\n",
       " '12th',\n",
       " '13',\n",
       " '130',\n",
       " '1300',\n",
       " '1301',\n",
       " '1305',\n",
       " '130500',\n",
       " '131',\n",
       " '132',\n",
       " '133',\n",
       " '134',\n",
       " '135',\n",
       " '135s',\n",
       " '136',\n",
       " '13603',\n",
       " '1364',\n",
       " '137',\n",
       " '138',\n",
       " '139',\n",
       " '1393',\n",
       " '13th',\n",
       " '13y',\n",
       " '13½',\n",
       " '14',\n",
       " '140',\n",
       " '1400',\n",
       " '1400s',\n",
       " '140230',\n",
       " '141',\n",
       " '142',\n",
       " '1425817301725',\n",
       " '143',\n",
       " '143m',\n",
       " '144',\n",
       " '14482302',\n",
       " '145',\n",
       " '146',\n",
       " '1460',\n",
       " '147',\n",
       " '148',\n",
       " '149',\n",
       " '14k',\n",
       " '14kwh',\n",
       " '14m',\n",
       " '14th',\n",
       " '15',\n",
       " '150',\n",
       " '1500',\n",
       " '1500s',\n",
       " '150th',\n",
       " '151',\n",
       " '1513',\n",
       " '1517',\n",
       " '152',\n",
       " '1521',\n",
       " '1522',\n",
       " '153',\n",
       " '1538',\n",
       " '1543',\n",
       " '155',\n",
       " '1552',\n",
       " '1555',\n",
       " '1559',\n",
       " '156',\n",
       " '1562',\n",
       " '1563',\n",
       " '1566',\n",
       " '1569',\n",
       " '157',\n",
       " '1576',\n",
       " '1578',\n",
       " '158',\n",
       " '1584',\n",
       " '1588',\n",
       " '15893',\n",
       " '159',\n",
       " '1591',\n",
       " '15975445007',\n",
       " '15e',\n",
       " '15ft',\n",
       " '15million',\n",
       " '15mm',\n",
       " '15pm',\n",
       " '15s',\n",
       " '15th',\n",
       " '15yrs',\n",
       " '16',\n",
       " '160',\n",
       " '1600',\n",
       " '1600s',\n",
       " '1605',\n",
       " '1606',\n",
       " '160716',\n",
       " '161',\n",
       " '1610',\n",
       " '161029',\n",
       " '162',\n",
       " '1621',\n",
       " '16236675004',\n",
       " '1624575',\n",
       " '162lvbnkan',\n",
       " '163',\n",
       " '164',\n",
       " '165',\n",
       " '1650',\n",
       " '1652',\n",
       " '166',\n",
       " '167',\n",
       " '168',\n",
       " '1689',\n",
       " '169',\n",
       " '16bn',\n",
       " '16k',\n",
       " '16s',\n",
       " '16th',\n",
       " '17',\n",
       " '170',\n",
       " '1700',\n",
       " '171',\n",
       " '1711',\n",
       " '172',\n",
       " '1720',\n",
       " '173',\n",
       " '1730s',\n",
       " '174',\n",
       " '1745',\n",
       " '175',\n",
       " '1752',\n",
       " '176',\n",
       " '1763',\n",
       " '1766',\n",
       " '177',\n",
       " '1770',\n",
       " '1775',\n",
       " '1776',\n",
       " '1777',\n",
       " '178',\n",
       " '1780',\n",
       " '1784',\n",
       " '1786',\n",
       " '1787',\n",
       " '1788',\n",
       " '1789',\n",
       " '179',\n",
       " '1790',\n",
       " '1791',\n",
       " '1793',\n",
       " '1793qianlong',\n",
       " '1795583',\n",
       " '1797',\n",
       " '1798',\n",
       " '1799',\n",
       " '17b2908f',\n",
       " '17k',\n",
       " '17s',\n",
       " '17th',\n",
       " '18',\n",
       " '180',\n",
       " '1800',\n",
       " '1800s',\n",
       " '1801',\n",
       " '1804',\n",
       " '1806',\n",
       " '1808',\n",
       " '1812',\n",
       " '1814',\n",
       " '1815',\n",
       " '1816',\n",
       " '1817',\n",
       " '1818',\n",
       " '182',\n",
       " '1820',\n",
       " '1820s',\n",
       " '1823',\n",
       " '1824',\n",
       " '1825',\n",
       " '1827',\n",
       " '1829',\n",
       " '182nd',\n",
       " '183',\n",
       " '1830',\n",
       " '1830s',\n",
       " '1831',\n",
       " '1835',\n",
       " '1837',\n",
       " '1838',\n",
       " '1839',\n",
       " '184',\n",
       " '1840',\n",
       " '1840s',\n",
       " '1841',\n",
       " '1842',\n",
       " '1844',\n",
       " '1845',\n",
       " '1846',\n",
       " '1848',\n",
       " '1849',\n",
       " '185',\n",
       " '1850',\n",
       " '1850s',\n",
       " '1851',\n",
       " '1853',\n",
       " '1854',\n",
       " '1855',\n",
       " '1856',\n",
       " '1857',\n",
       " '1858',\n",
       " '1859',\n",
       " '186',\n",
       " '1860',\n",
       " '1860s',\n",
       " '1861',\n",
       " '1862',\n",
       " '1863',\n",
       " '1864',\n",
       " '1865',\n",
       " '1868',\n",
       " '187',\n",
       " '1870',\n",
       " '1870s',\n",
       " '1871',\n",
       " '1872',\n",
       " '1873',\n",
       " '1876',\n",
       " '1877',\n",
       " '1878',\n",
       " '188',\n",
       " '1880',\n",
       " '1881',\n",
       " '1883',\n",
       " '1884',\n",
       " '1885',\n",
       " '1886',\n",
       " '1887',\n",
       " '189',\n",
       " '1890',\n",
       " '1890s',\n",
       " '1892',\n",
       " '1893',\n",
       " '1895',\n",
       " '1896',\n",
       " '1897',\n",
       " '1898',\n",
       " '1899',\n",
       " '18f',\n",
       " '18m',\n",
       " '18th',\n",
       " '19',\n",
       " '190',\n",
       " '1900',\n",
       " '1900s',\n",
       " '1901',\n",
       " '1903',\n",
       " '1904',\n",
       " '1905',\n",
       " '1907',\n",
       " '1908',\n",
       " '1909',\n",
       " '190th',\n",
       " '191',\n",
       " '1910',\n",
       " '1910s',\n",
       " '1911',\n",
       " '1912',\n",
       " '1913',\n",
       " '1914',\n",
       " '1915',\n",
       " '1916',\n",
       " '1917',\n",
       " '1918',\n",
       " '1919',\n",
       " '191bn',\n",
       " '192',\n",
       " '1920',\n",
       " '1920s',\n",
       " '1921',\n",
       " '1922',\n",
       " '1923',\n",
       " '1924',\n",
       " '1925',\n",
       " '1926',\n",
       " '1927',\n",
       " '1928',\n",
       " '1929',\n",
       " '193',\n",
       " '1930',\n",
       " '1930s',\n",
       " '1931',\n",
       " '1932',\n",
       " '1933',\n",
       " '1934',\n",
       " '1935',\n",
       " '1936',\n",
       " '1937',\n",
       " '1938',\n",
       " '1939',\n",
       " '194',\n",
       " '1940',\n",
       " '1940s',\n",
       " '1941',\n",
       " '1942',\n",
       " '1943',\n",
       " '1944',\n",
       " '1945',\n",
       " '1946',\n",
       " '1947',\n",
       " '1948',\n",
       " '1949',\n",
       " '195',\n",
       " '1950',\n",
       " '1950s',\n",
       " '1951',\n",
       " '1952',\n",
       " '1953',\n",
       " '1954',\n",
       " '1955',\n",
       " '1956',\n",
       " '1957',\n",
       " '1958',\n",
       " '19580395003',\n",
       " '19580405001',\n",
       " '1959',\n",
       " '196',\n",
       " '1960',\n",
       " '1960s',\n",
       " '1961',\n",
       " '19617315012',\n",
       " '1962',\n",
       " '1963',\n",
       " '1964',\n",
       " '1965',\n",
       " '1966',\n",
       " '1967',\n",
       " '1968',\n",
       " '1969',\n",
       " '197',\n",
       " '1970',\n",
       " '1970s',\n",
       " '1971',\n",
       " '1972',\n",
       " '1973',\n",
       " '1974',\n",
       " '1975',\n",
       " '1976',\n",
       " '1977',\n",
       " '1978',\n",
       " '1979',\n",
       " '1980',\n",
       " '1980s',\n",
       " '1981',\n",
       " '1982',\n",
       " '1983',\n",
       " '1984',\n",
       " '1985',\n",
       " '1986',\n",
       " '1987',\n",
       " '1988',\n",
       " '1989',\n",
       " '198974609375',\n",
       " '199',\n",
       " '1990',\n",
       " '1990s',\n",
       " '1991',\n",
       " '1992',\n",
       " '1993',\n",
       " '1994',\n",
       " '1995',\n",
       " '1996',\n",
       " '1997',\n",
       " '1998',\n",
       " '1999',\n",
       " '19th',\n",
       " '1_2',\n",
       " '1alvwe4bralkh',\n",
       " '1b',\n",
       " '1b1',\n",
       " '1bbswheiehlqifxzus3j35',\n",
       " '1billion',\n",
       " '1bjxt3uhim5fqn93gb0hkxakuarz99d7xcitzftye',\n",
       " '1bs',\n",
       " '1huziqim53',\n",
       " '1hztlj',\n",
       " '1is9krdfnysv0buhf8elizydmsrpwn944flw1tofjw46j4uaxsbrbp284wifmv8n',\n",
       " '1jquvafupk',\n",
       " '1k',\n",
       " '1m',\n",
       " '1m08s',\n",
       " '1mdb',\n",
       " '1mgfbvy',\n",
       " '1million',\n",
       " '1mm',\n",
       " '1mwvcarc3jsuon8rrxype4espweqzd6zsrbhgh4uqf56pcft2ubnqku4wtgoecsw',\n",
       " '1o6qorkewr',\n",
       " '1oo',\n",
       " '1oth',\n",
       " '1oxutnexun',\n",
       " '1st',\n",
       " '1tn',\n",
       " '1tr',\n",
       " '1wrwsaijjsohk5rzj',\n",
       " '1z',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2000s',\n",
       " '2001',\n",
       " '2002',\n",
       " '2003',\n",
       " '2004',\n",
       " '2005',\n",
       " '2006',\n",
       " '2007',\n",
       " '2008',\n",
       " '2009',\n",
       " '200k',\n",
       " '200m',\n",
       " '200x',\n",
       " '201',\n",
       " '2010',\n",
       " '2010s',\n",
       " '2011',\n",
       " '2012',\n",
       " '2012newstart',\n",
       " '2013',\n",
       " '2014',\n",
       " '2015',\n",
       " '20150308054059',\n",
       " '2016',\n",
       " '20161026_spain1',\n",
       " '20161026_spain3',\n",
       " '2016a',\n",
       " '2016b',\n",
       " '2016ers',\n",
       " '2017',\n",
       " '2018',\n",
       " '2019',\n",
       " '202',\n",
       " '2020',\n",
       " '2021',\n",
       " '2022',\n",
       " '2023',\n",
       " '2024',\n",
       " '2025',\n",
       " '203',\n",
       " '2030',\n",
       " '2032',\n",
       " '2033',\n",
       " '2034',\n",
       " '2035',\n",
       " '2036',\n",
       " '2040',\n",
       " '2042',\n",
       " '2043',\n",
       " '2045',\n",
       " '205',\n",
       " '2050',\n",
       " '20535',\n",
       " '206',\n",
       " '2064',\n",
       " '207',\n",
       " '2071',\n",
       " '208',\n",
       " '209',\n",
       " '20am',\n",
       " '20book',\n",
       " '20gs',\n",
       " '20k',\n",
       " '20million',\n",
       " '20p',\n",
       " '20power',\n",
       " '20s',\n",
       " '20th',\n",
       " '20tn',\n",
       " '21',\n",
       " '210',\n",
       " '2100',\n",
       " '2102',\n",
       " '211',\n",
       " '2110',\n",
       " '2117',\n",
       " '212',\n",
       " '213',\n",
       " '2130',\n",
       " '214',\n",
       " '2146815',\n",
       " '2149237058061490',\n",
       " '214r',\n",
       " '215',\n",
       " '216',\n",
       " '217',\n",
       " '218',\n",
       " '219',\n",
       " '21mn',\n",
       " '21s',\n",
       " '21st',\n",
       " '21wire',\n",
       " '22',\n",
       " '220',\n",
       " '2205',\n",
       " '221',\n",
       " '221day_m25',\n",
       " '222',\n",
       " '223',\n",
       " '224',\n",
       " '225',\n",
       " '226',\n",
       " '226t',\n",
       " '227',\n",
       " '227kg',\n",
       " '228',\n",
       " '229',\n",
       " '22_1171',\n",
       " '22am',\n",
       " '22autoupdate',\n",
       " '22basemap',\n",
       " '22default',\n",
       " '22event',\n",
       " '22feed',\n",
       " '22grayscale',\n",
       " '22list',\n",
       " '22listformat',\n",
       " '22m',\n",
       " '22m3',\n",
       " '22map',\n",
       " '22mapposition',\n",
       " '22nd',\n",
       " '22newest',\n",
       " '22overlays',\n",
       " '22plates',\n",
       " '22restrictlisttomap',\n",
       " '22search',\n",
       " '22sort',\n",
       " '22th',\n",
       " '22timezone',\n",
       " '22us1000778i',\n",
       " '22utc',\n",
       " '22viewmodes',\n",
       " '23',\n",
       " '230',\n",
       " '231',\n",
       " '232',\n",
       " '233',\n",
       " '234',\n",
       " '2344',\n",
       " '235',\n",
       " '236',\n",
       " '237',\n",
       " '238',\n",
       " '239',\n",
       " '23k',\n",
       " '23rd',\n",
       " '24',\n",
       " '240',\n",
       " '241',\n",
       " '242',\n",
       " '243',\n",
       " '244',\n",
       " '24454002',\n",
       " '244th',\n",
       " '245',\n",
       " '2450',\n",
       " '246',\n",
       " '247',\n",
       " '2472',\n",
       " '24888',\n",
       " '249',\n",
       " '24news',\n",
       " '24th',\n",
       " '25',\n",
       " '250',\n",
       " '25018606',\n",
       " '250m',\n",
       " '251',\n",
       " '2510',\n",
       " '252',\n",
       " '253207',\n",
       " '254',\n",
       " '25421',\n",
       " '2544',\n",
       " '255',\n",
       " '2552',\n",
       " '256',\n",
       " '257',\n",
       " '25751119',\n",
       " '258',\n",
       " '25am',\n",
       " '25m',\n",
       " '25th',\n",
       " '26',\n",
       " '260',\n",
       " '261',\n",
       " '262',\n",
       " '263',\n",
       " '2635',\n",
       " '264',\n",
       " '265',\n",
       " '2656002',\n",
       " '267',\n",
       " '2670',\n",
       " '268',\n",
       " '269',\n",
       " '26t18',\n",
       " '26th',\n",
       " '27',\n",
       " '270',\n",
       " '2700',\n",
       " '2700922',\n",
       " '27026',\n",
       " '2703',\n",
       " '271',\n",
       " '2711',\n",
       " '27111',\n",
       " '272',\n",
       " '273',\n",
       " '274',\n",
       " '275',\n",
       " '276',\n",
       " '277',\n",
       " '278',\n",
       " '279',\n",
       " '27th',\n",
       " '28',\n",
       " '280',\n",
       " '281',\n",
       " '282',\n",
       " '283',\n",
       " '284',\n",
       " '28403',\n",
       " '285',\n",
       " '286',\n",
       " '28657',\n",
       " '287',\n",
       " '288',\n",
       " '289',\n",
       " '28am',\n",
       " '28th',\n",
       " '29',\n",
       " '290',\n",
       " '2900',\n",
       " '2900100001',\n",
       " '291',\n",
       " '292',\n",
       " '293',\n",
       " '29385',\n",
       " '29385ote',\n",
       " '294',\n",
       " '295',\n",
       " '2950100001',\n",
       " '29549',\n",
       " '296',\n",
       " '298',\n",
       " '29th',\n",
       " '2a',\n",
       " '2b',\n",
       " '2bowles',\n",
       " '2c',\n",
       " '2ccrww3wqeay',\n",
       " '2ckus9qi9g',\n",
       " '2cs',\n",
       " '2degrees',\n",
       " '2f',\n",
       " '2f102516_6',\n",
       " '2f16',\n",
       " '2fnews',\n",
       " '2fpreventdisease',\n",
       " '2gary2',\n",
       " '2gkhtimovh',\n",
       " '2hibftjxscml3k8k6mbdi8p9zvcmjsxbppcyrffw9a6t',\n",
       " '2hzuvxyp8k',\n",
       " '2k',\n",
       " '2kkpwafd9pxaqnwjmpd4amk60l3n',\n",
       " '2l',\n",
       " '2m52s',\n",
       " '2nd',\n",
       " '2o16',\n",
       " '2paragraphs',\n",
       " '2percent',\n",
       " '2plwa3cerym6byp60362co7cpzochyhsvgppzyh0qex',\n",
       " '2s',\n",
       " '2x',\n",
       " '2yiugiyosv',\n",
       " '2yxlvcf03qflflgzzfn7fcv5jw',\n",
       " '2zksz3xesc7mmpgrzanh4pk1dlr',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '3001',\n",
       " '300k',\n",
       " '300kg',\n",
       " '301',\n",
       " '302',\n",
       " '3037',\n",
       " '304',\n",
       " '305',\n",
       " '306',\n",
       " '307',\n",
       " '308',\n",
       " '309',\n",
       " '309533',\n",
       " '30am',\n",
       " '30grams',\n",
       " '30k',\n",
       " '30mki',\n",
       " '30p',\n",
       " '30pm',\n",
       " '30s',\n",
       " '30sm',\n",
       " '30th',\n",
       " '31',\n",
       " '310',\n",
       " '312',\n",
       " '313',\n",
       " '314',\n",
       " '315',\n",
       " '316',\n",
       " '317',\n",
       " '31715',\n",
       " '31721',\n",
       " '318',\n",
       " '319',\n",
       " '31am',\n",
       " '31s',\n",
       " '31st',\n",
       " '31yrs',\n",
       " '32',\n",
       " '320',\n",
       " '321',\n",
       " '3222705',\n",
       " '3225440',\n",
       " '323',\n",
       " '324',\n",
       " '325',\n",
       " '326',\n",
       " '328',\n",
       " '32833',\n",
       " '329',\n",
       " '32937',\n",
       " '32nd',\n",
       " '33',\n",
       " '330',\n",
       " '33010',\n",
       " '330m',\n",
       " '331',\n",
       " '33127',\n",
       " '332',\n",
       " '333',\n",
       " '334',\n",
       " '334m',\n",
       " '33552',\n",
       " '336',\n",
       " '33656002',\n",
       " '337',\n",
       " '3370',\n",
       " '33713',\n",
       " '33722',\n",
       " '33739',\n",
       " '338',\n",
       " '339',\n",
       " '33k',\n",
       " '33rd',\n",
       " '33s',\n",
       " '33yo',\n",
       " '34',\n",
       " '340',\n",
       " '34000',\n",
       " '342',\n",
       " '343',\n",
       " '344',\n",
       " '345',\n",
       " '3454',\n",
       " '346',\n",
       " '347',\n",
       " '348',\n",
       " '349',\n",
       " '34th',\n",
       " '35',\n",
       " '350',\n",
       " '3500',\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## initialize a TfidfVectorizer object: tfidf_vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words = 'english', max_df=0.7)\n",
    "\n",
    "## transform the training data: tfidf_train \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train.values)\n",
    "\n",
    "## transform the test data: tfidf_test \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test.values)\n",
    "\n",
    "## print the first 10 features\n",
    "tfidf_vectorizer.get_feature_names()[:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "## print the first 5 vectors of the tfidf training data\n",
    "print(tfidf_train.A[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00000031</th>\n",
       "      <th>000035</th>\n",
       "      <th>00006</th>\n",
       "      <th>0001</th>\n",
       "      <th>0001pt</th>\n",
       "      <th>000ft</th>\n",
       "      <th>000km</th>\n",
       "      <th>...</th>\n",
       "      <th>حلب</th>\n",
       "      <th>عربي</th>\n",
       "      <th>عن</th>\n",
       "      <th>لم</th>\n",
       "      <th>ما</th>\n",
       "      <th>محاولات</th>\n",
       "      <th>من</th>\n",
       "      <th>هذا</th>\n",
       "      <th>والمرضى</th>\n",
       "      <th>ยงade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56922 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0000  00000031  000035  00006  0001  0001pt  000ft  000km  ...  \\\n",
       "0   0    0     0         0       0      0     0       0      0      0  ...   \n",
       "1   0    0     0         0       0      0     0       0      0      0  ...   \n",
       "2   0    0     0         0       0      0     0       0      0      0  ...   \n",
       "3   0    0     0         0       0      0     0       0      0      0  ...   \n",
       "4   0    0     0         0       0      0     0       0      0      0  ...   \n",
       "\n",
       "   حلب  عربي  عن  لم  ما  محاولات  من  هذا  والمرضى  ยงade  \n",
       "0    0     0   0   0   0        0   0    0        0      0  \n",
       "1    0     0   0   0   0        0   0    0        0      0  \n",
       "2    0     0   0   0   0        0   0    0        0      0  \n",
       "3    0     0   0   0   0        0   0    0        0      0  \n",
       "4    0     0   0   0   0        0   0    0        0      0  \n",
       "\n",
       "[5 rows x 56922 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the CountVectorizer DataFrame: count_df\n",
    "count_df = pd.DataFrame(count_train.A, columns=count_vectorizer.get_feature_names())\n",
    "\n",
    "# Print the head of count_df\n",
    "count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00000031</th>\n",
       "      <th>000035</th>\n",
       "      <th>00006</th>\n",
       "      <th>0001</th>\n",
       "      <th>0001pt</th>\n",
       "      <th>000ft</th>\n",
       "      <th>000km</th>\n",
       "      <th>...</th>\n",
       "      <th>حلب</th>\n",
       "      <th>عربي</th>\n",
       "      <th>عن</th>\n",
       "      <th>لم</th>\n",
       "      <th>ما</th>\n",
       "      <th>محاولات</th>\n",
       "      <th>من</th>\n",
       "      <th>هذا</th>\n",
       "      <th>والمرضى</th>\n",
       "      <th>ยงade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56922 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  0000  00000031  000035  00006  0001  0001pt  000ft  000km  ...  \\\n",
       "0  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n",
       "1  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n",
       "2  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n",
       "3  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n",
       "4  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n",
       "\n",
       "   حلب  عربي   عن   لم   ما  محاولات   من  هذا  والمرضى  ยงade  \n",
       "0  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
       "1  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
       "2  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
       "3  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
       "4  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
       "\n",
       "[5 rows x 56922 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the TfidfVectorizer DataFrame: tfidf_df\n",
    "tfidf_df = pd.DataFrame(tfidf_train.A, columns=tfidf_vectorizer.get_feature_names())\n",
    "\n",
    "# Print the head of tfidf_df\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the difference in columns: difference\n",
    "difference = set(tfidf_df.columns) - set(count_df.columns)\n",
    "difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check whether the DataFrames are equal\n",
    "count_df.equals(tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.893352462936394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 865,  143],\n",
       "       [  80, 1003]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a Multinomial Naive Bayes classifier: nb_classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "nb_classifier.fit(count_train, y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(count_test)\n",
    "\n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=['FAKE','REAL'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8565279770444764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 739,  269],\n",
       "       [  31, 1052]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Multinomial Naive Bayes classifier: nb_classifier\n",
    "nb_classifier_tfidf = MultinomialNB()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "nb_classifier_tfidf.fit(tfidf_train, y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred_tfidf = nb_classifier_tfidf.predict(tfidf_test)\n",
    "\n",
    "# Calculate the accuracy score: score\n",
    "score_tfidf = metrics.accuracy_score(y_test, pred_tfidf)\n",
    "print(score_tfidf)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "cm_tfidf = metrics.confusion_matrix(y_test, pred_tfidf, labels=['FAKE', 'REAL'])\n",
    "cm_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:  0.1\n",
      "Score:  0.8976566236250598\n",
      "\n",
      "Alpha:  0.2\n",
      "Score:  0.8938307030129125\n",
      "\n",
      "Alpha:  0.30000000000000004\n",
      "Score:  0.8900047824007652\n",
      "\n",
      "Alpha:  0.4\n",
      "Score:  0.8857006217120995\n",
      "\n",
      "Alpha:  0.5\n",
      "Score:  0.8842659014825442\n",
      "\n",
      "Alpha:  0.6\n",
      "Score:  0.874701099952176\n",
      "\n",
      "Alpha:  0.7000000000000001\n",
      "Score:  0.8703969392635102\n",
      "\n",
      "Alpha:  0.8\n",
      "Score:  0.8660927785748446\n",
      "\n",
      "Alpha:  0.9\n",
      "Score:  0.8589191774270684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the list of alphas: alphas\n",
    "alphas = np.arange(0.1, 1, 0.1)\n",
    "\n",
    "# Define train_and_predict()\n",
    "def train_and_predict(alpha):\n",
    "    # Instantiate the classifier: nb_classifier\n",
    "    nb_classifier = MultinomialNB(alpha=alpha)\n",
    "    # Fit to the training data\n",
    "    nb_classifier.fit(tfidf_train, y_train)\n",
    "    # Predict the labels: pred\n",
    "    pred = nb_classifier.predict(tfidf_test)\n",
    "    # Compute accuracy: score\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    return score\n",
    "\n",
    "# Iterate over the alphas and print the corresponding score\n",
    "for alpha in alphas:\n",
    "    print('Alpha: ', alpha)\n",
    "    print('Score: ', train_and_predict(alpha))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAKE [(-11.316312804238807, '0000'), (-11.316312804238807, '000035'), (-11.316312804238807, '0001'), (-11.316312804238807, '0001pt'), (-11.316312804238807, '000km'), (-11.316312804238807, '0011'), (-11.316312804238807, '006s'), (-11.316312804238807, '007'), (-11.316312804238807, '007s'), (-11.316312804238807, '008s'), (-11.316312804238807, '0099'), (-11.316312804238807, '00am'), (-11.316312804238807, '00p'), (-11.316312804238807, '00pm'), (-11.316312804238807, '014'), (-11.316312804238807, '015'), (-11.316312804238807, '018'), (-11.316312804238807, '01am'), (-11.316312804238807, '020'), (-11.316312804238807, '023')]\n",
      "REAL [(-7.742481952533027, 'states'), (-7.717550034444668, 'rubio'), (-7.703583809227384, 'voters'), (-7.654774992495461, 'house'), (-7.649398936153309, 'republicans'), (-7.6246184189367, 'bush'), (-7.616556675728881, 'percent'), (-7.545789237823644, 'people'), (-7.516447881078008, 'new'), (-7.448027933291952, 'party'), (-7.411148410203476, 'cruz'), (-7.410910239085596, 'state'), (-7.35748985914622, 'republican'), (-7.33649923948987, 'campaign'), (-7.2854057032685775, 'president'), (-7.2166878130917755, 'sanders'), (-7.108263114902301, 'obama'), (-6.724771332488041, 'clinton'), (-6.5653954389926845, 'said'), (-6.328486029596207, 'trump')]\n"
     ]
    }
   ],
   "source": [
    "# Get the class labels: class_labels\n",
    "class_labels = nb_classifier_tfidf.classes_\n",
    "\n",
    "# Extract the features: feature_names\n",
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# Zip the feature names together with the coefficient array and sort by weights: feat_with_weights\n",
    "feat_with_weights = sorted(zip(nb_classifier_tfidf.coef_[0], feature_names))\n",
    "\n",
    "# Print the first class label and the top 20 feat_with_weights entries\n",
    "print(class_labels[0], feat_with_weights[:20])\n",
    "\n",
    "# Print the second class label and the bottom 20 feat_with_weights entries\n",
    "print(class_labels[1], feat_with_weights[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
